{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from rtfm import featurizer as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "vprint = print if verbose else lambda *args, **kwargs: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    def __init__(self, \n",
    "                 simulator,\n",
    "                 valid_actions,\n",
    "                 ucb_c,\n",
    "                 discount,\n",
    "                 max_actions,\n",
    "                 root=None,\n",
    "                 render=False):\n",
    "        \"\"\"\n",
    "        Monte Carlo Tree Search assuming deterministic dynamics.\n",
    "        \n",
    "        simulator: \n",
    "            wrapper of the environment that returns a scalar reward, a list of valid actions \n",
    "            and a 'done' boolean flag when presented with an action\n",
    "        valid_moves:\n",
    "            list of valid moves for the root node\n",
    "        ucb_c:\n",
    "            Constantused in the UCB1 formula for trees\n",
    "            UCB(s,a) = Q(s,a) + ucb_c*sqrt(log N(s,a)/(\\sum_b N(s,b)))\n",
    "        discount:\n",
    "            discoung factor gamma of the MDP\n",
    "        max_actions:\n",
    "            number of actions to be taken at most from the root node to the end of a rollout\n",
    "        root: \n",
    "            might be the child of an old root node; use it to keep all the cached computations \n",
    "            from previous searches with a different root node. \n",
    "        \"\"\"\n",
    "        self.simulator = simulator\n",
    "        self.original_dict = simulator.save_state_dict()\n",
    "        self.valid_actions = valid_actions\n",
    "        self.action_space = len(valid_actions)\n",
    "        self.ucb_c = ucb_c\n",
    "        self.discount = discount\n",
    "        self.max_actions = max_actions\n",
    "        self.root = root\n",
    "        self.render = render\n",
    "    \n",
    "    def get_subtree(self, action):\n",
    "        \"\"\"\n",
    "        Returns the subtree whose root node is the current root's child corresponding to\n",
    "        the given action.\n",
    "        \"\"\"\n",
    "        return self.root.children[action]\n",
    "    \n",
    "    def run(self, num_simulations):\n",
    "        \"\"\"\n",
    "        Runs num_simulations searches starting from the root node corresponding to the internal\n",
    "        state of the simulator given during initialization.\n",
    "        Returns the root node and an extra_info dictionary\n",
    "        \"\"\"\n",
    "        if self.root is None:\n",
    "            self.root = Node()\n",
    "            self.root.expand(\n",
    "                self.valid_actions,\n",
    "                0, # reward to get to root\n",
    "                False, # terminal node\n",
    "                self.simulator # state of the simulator at the root node \n",
    "            )\n",
    "            # not sure about this\n",
    "            self.root.visit_count += 1\n",
    "        \n",
    "        max_tree_depth = 0\n",
    "        root = self.root\n",
    "        for n in range(num_simulations):\n",
    "            ### Start of a simulation/search ###\n",
    "            vprint(\"\\nSimulation %d started.\"%(n+1))\n",
    "            node = root\n",
    "            # make sure that the simulator internal state is reset to the original one\n",
    "            self.simulator.load_state_dict(root.simulator_dict)\n",
    "            search_path = [node]\n",
    "            current_tree_depth = 0\n",
    "            if self.render:\n",
    "                node.render(self.simulator)\n",
    "            ### Selection phase until leaf node is reached ###\n",
    "            while node.expanded or (current_tree_depth<self.max_actions):\n",
    "                current_tree_depth += 1\n",
    "                action, node = self.select(node)\n",
    "                if self.render and node.expanded:\n",
    "                    node.render(self.simulator)\n",
    "                vprint(\"Current tree depth: \", current_tree_depth)\n",
    "                vprint(\"Action selected: \", action)\n",
    "                vprint(\"Child node terminal: \", node.terminal)\n",
    "                vprint(\"Child node expanded: \", node.expanded)\n",
    "                if node.expanded or node.terminal:\n",
    "                    search_path.append(node)\n",
    "                    if node.terminal:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            ### Expansion of leaf node (if not terminal)###\n",
    "            vprint(\"Expansion phase started\")\n",
    "            if not node.terminal:\n",
    "                parent = search_path[-1] # last expanded node on the search path\n",
    "                node = self.expand(node, parent, action)\n",
    "                if self.render:\n",
    "                    node.render(self.simulator)\n",
    "                search_path.append(node)\n",
    "            \n",
    "            ### Simulation phase for self.max_actions - current_tree_depth steps ###\n",
    "            vprint(\"Simulation  phase started\")\n",
    "            value = self.simulate(node, current_tree_depth)\n",
    "            vprint(\"Simulated value: \", value)\n",
    "            \n",
    "            ### Backpropagation of the leaf node value along the seach_path ###\n",
    "            vprint(\"Backpropagation phase started\")\n",
    "            self.backprop(search_path, value)\n",
    "        \n",
    "            max_tree_depth = max(max_tree_depth, current_tree_depth)\n",
    "            vprint(\"Simulation %d done.\"%(n+1))\n",
    "        extra_info = {\n",
    "            \"max_tree_depth\": max_tree_depth\n",
    "        }\n",
    "        # just a check to see if root works as a shallow copy of self.root\n",
    "        assert root.visit_count == self.root.visit_count, \"self.root not updated during search\"\n",
    "        \n",
    "        # make sure that the simulator internal state is reset to the original one\n",
    "        self.simulator.load_state_dict(root.simulator_dict)\n",
    "        return root, extra_info\n",
    "        \n",
    "    def select(self, node):\n",
    "        \"\"\"\n",
    "        Use UCT formula on the input node; return the action selected and the corresponding child node \n",
    "        \"\"\"\n",
    "        actions = []\n",
    "        ucb_values = []\n",
    "        for action, child in node.children.items():\n",
    "            actions.append(action)\n",
    "            ucb_values.append(self.ucb_score(node, child))\n",
    "        actions = np.array(actions)\n",
    "        vprint(\"actions: \", actions)\n",
    "        \n",
    "        ucb_values = np.array(ucb_values)\n",
    "        vprint(\"ucb_values: \", ucb_values)\n",
    "        \n",
    "        max_U = ucb_values.max()\n",
    "        vprint(\"max_U: \", max_U)\n",
    "        \n",
    "        mask = (ucb_values==max_U)\n",
    "        vprint(\"mask: \", mask)\n",
    "        \n",
    "        best_actions = actions[mask]\n",
    "        vprint(\"best_actions: \", best_actions)\n",
    "        \n",
    "        action = np.random.choice(best_actions)\n",
    "        return action, node.children[action]\n",
    "\n",
    "    def ucb_score(self, parent, child, eps=1e-3):\n",
    "        \"\"\"\n",
    "        The score for a node is based on its value, plus an exploration bonus.\n",
    "        \"\"\"\n",
    "        exploration_term = self.ucb_c*np.sqrt(np.log(parent.visit_count)/(child.visit_count+eps))\n",
    "\n",
    "        if child.visit_count > 0:\n",
    "            # Mean value Q\n",
    "            value_term = child.reward + self.discount*child.value() \n",
    "        else:\n",
    "            value_term = 0\n",
    "\n",
    "        return value_term + exploration_term\n",
    "    \n",
    "    def expand(self, node, parent, action):\n",
    "        \"\"\"\n",
    "        Expand the node obtained by taking the given action from the parent node \n",
    "        \"\"\"\n",
    "        simulator = parent.get_simulator(self.simulator) # get a deepcopy of the simulator with the parent's state stored\n",
    "        valid_actions, reward, done = simulator.step(action) # this also updates the simulator's internal state\n",
    "        vprint(\"reward: \", reward)\n",
    "        vprint(\"done: \", done)\n",
    "        node.expand(valid_actions, reward, done, simulator)\n",
    "        return node\n",
    "    \n",
    "    def simulate(self, node, current_depth):\n",
    "        \"\"\"\n",
    "        Simulate a rollout with a random policy starting from the input node\n",
    "        until the end of the episode or self.max_actions are reached \n",
    "        (also considering the current depth of the input node from the root)\n",
    "        \"\"\"\n",
    "        if not node.terminal:\n",
    "            simulator = node.get_simulator(self.simulator)\n",
    "            valid_actions = node.valid_actions\n",
    "            steps = self.max_actions - current_depth\n",
    "            cum_discounted_reward = 0\n",
    "            for i in range(steps):\n",
    "                action = np.random.choice(valid_actions)\n",
    "                valid_actions, reward, done = simulator.step(action)\n",
    "                cum_discounted_reward += (self.discount**i)*reward\n",
    "                if done:\n",
    "                    break\n",
    "        else:\n",
    "            cum_discounted_reward = 0\n",
    "        return cum_discounted_reward\n",
    "            \n",
    "    def backprop(self, search_path, value):\n",
    "        \"\"\"\n",
    "        Update the value sum and visit count of all nodes along the search path.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value\n",
    "            node.visit_count += 1\n",
    "            value = node.reward + self.discount*value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.reward = 0\n",
    "        self.simulator = None\n",
    "        self.expanded = False\n",
    "        self.terminal = False\n",
    "        self.simulator_dict = None\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def expand(self, valid_actions, reward, done, simulator):\n",
    "        self.expanded = True\n",
    "        vprint(\"Valid actions as child: \", valid_actions)\n",
    "        vprint(\"Terminal node: \", done)\n",
    "        self.reward = reward\n",
    "        self.terminal = done\n",
    "        self.valid_actions = valid_actions\n",
    "        if not done:\n",
    "            for action in valid_actions:\n",
    "                self.children[action] = Node()\n",
    "        self.simulator_dict = simulator.save_state_dict()\n",
    "        \n",
    "    def get_simulator(self, simulator):\n",
    "        if self.simulator_dict is not None:\n",
    "            # load a deepcoy of the simulator_dict, so that the internal variable remains unchanged\n",
    "            simulator.load_state_dict(copy.deepcopy(self.simulator_dict)) \n",
    "            return simulator\n",
    "        else:\n",
    "            print(\"Trying to load simulator_dict, but it was never instantiated.\")\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    def best_action(self, discount):\n",
    "        \"\"\"\n",
    "        Look among the children and take the one with higher Q-value. \n",
    "        Exclude children with 0 visits.\n",
    "        \"\"\"\n",
    "        actions = []\n",
    "        Qvalues = []\n",
    "        for action, child in self.children.items():\n",
    "            actions.append(action)\n",
    "            Qvalues.append(child.reward + discount*child.value())\n",
    "        actions = np.array(actions)\n",
    "        Qvalues = np.array(Qvalues)\n",
    "        max_Q = Qvalues.max()\n",
    "        mask = (Qvalues==max_Q)\n",
    "        best_actions = actions[mask]\n",
    "        return np.random.choice(best_actions)\n",
    "    \n",
    "    def render(self, simulator):\n",
    "        if self.simulator_dict is not None:\n",
    "            simulator.load_state_dict(self.simulator_dict)\n",
    "            simulator.render()\n",
    "        else:\n",
    "            raise Exception(\"Node simulator not initialized yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueSimulator():\n",
    "    def __init__(self, env, featurizer=None):\n",
    "        self.env = env\n",
    "        self.action_space = len(gym_env.action_space)\n",
    "        self.featurizer = featurizer\n",
    "        \n",
    "    def reset(self):\n",
    "        frame = self.env.reset()\n",
    "        valid_moves = frame['valid'].numpy().astype(bool) # boolean mask of shape (action_space)\n",
    "        actions = np.arange(self.action_space)\n",
    "        valid_actions = actions[valid_moves]\n",
    "        return valid_actions\n",
    "    \n",
    "    def step(self, action):\n",
    "        frame, reward, done, _ = self.env.step(int(action))\n",
    "        valid_moves = frame['valid'].numpy().astype(bool) # boolean mask of shape (action_space)\n",
    "        actions = np.arange(self.action_space)\n",
    "        valid_actions = actions[valid_moves]\n",
    "        return valid_actions, reward, done\n",
    "    \n",
    "    def render(self):\n",
    "        self.featurizer.featurize(self.env)\n",
    "        \n",
    "    def save_state_dict(self):\n",
    "        return self.env.save_state_dict()\n",
    "        \n",
    "    def load_state_dict(self, d):\n",
    "        self.env.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define parameters ###\n",
    "ucb_C = 1.0\n",
    "discount = 0.997\n",
    "episode_length = 50\n",
    "max_actions = 100\n",
    "num_simulations = 50\n",
    "\n",
    "flags = utils.Flags(env=\"rtfm:groups_simple_stationary-v0\")\n",
    "gym_env = utils.create_env(flags)\n",
    "#gym_env = utils.create_env(flags, featurizer=X.Concat([X.Text(), X.ValidMoves(), X.Render()]))\n",
    "featurizer = X.Render()\n",
    "game_simulator = TrueSimulator(gym_env, featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "██████\n",
      "█   ?█\n",
      "█    █\n",
      "█n @ █\n",
      "█ ! y█\n",
      "██████\n",
      "\n"
     ]
    }
   ],
   "source": [
    "game_simulator.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_root_summary(root, discount):\n",
    "    action_dict = {\n",
    "        0:\"Stay\",\n",
    "        1:\"Up\",\n",
    "        2:\"Down\",\n",
    "        3:\"Left\",\n",
    "        4:\"Right\"\n",
    "    }\n",
    "    \n",
    "    for action, child in root.children.items():\n",
    "        Q =  child.reward + discount*child.value()\n",
    "        visits = child.visit_count\n",
    "        print(\"Action \", action_dict[action], \": Q-value=%.3f - Visit counts=%d\"%(Q,visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode_v0(\n",
    "    env,\n",
    "    episode_length,\n",
    "    ucb_C,\n",
    "    discount,\n",
    "    max_actions,\n",
    "    num_simulations,\n",
    "    render = True,\n",
    "    debug_render=False\n",
    "):\n",
    "    action_dict = {\n",
    "        0:\"Stay\",\n",
    "        1:\"Up\",\n",
    "        2:\"Down\",\n",
    "        3:\"Left\",\n",
    "        4:\"Right\"\n",
    "    }\n",
    "    valid_actions = env.reset()\n",
    "    if render:\n",
    "        env.render()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    for i in range(episode_length):\n",
    "        mcts = MCTS(env, valid_actions, ucb_C, discount, max_actions, render=debug_render)\n",
    "        print(\"\\n\",\"-\"*40)\n",
    "        print(\"Performing MCTS step\")\n",
    "        root, info = mcts.run(num_simulations)\n",
    "        show_root_summary(root, discount)\n",
    "        print(\"-\"*40)\n",
    "        print(\"Tree info: \", info)\n",
    "        action = root.best_action(discount)\n",
    "        print(\"Action selected from MCTS: \", action, \"({})\".format(action_dict[action]))\n",
    "        valid_actions, reward, done = env.step(action)\n",
    "        if render:\n",
    "            env.render()\n",
    "        print(\"Reward received: \", reward)\n",
    "        print(\"Done: \", done)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode_v1(\n",
    "    env,\n",
    "    episode_length,\n",
    "    ucb_C,\n",
    "    discount,\n",
    "    max_actions,\n",
    "    num_simulations,\n",
    "    render = True,\n",
    "    debug_render=False\n",
    "):\n",
    "    \"\"\"\n",
    "    W.r.t. version 0 it re-uses the information cached in the child node selected \n",
    "    \"\"\"\n",
    "    action_dict = {\n",
    "        0:\"Stay\",\n",
    "        1:\"Up\",\n",
    "        2:\"Down\",\n",
    "        3:\"Left\",\n",
    "        4:\"Right\"\n",
    "    }\n",
    "    valid_actions = env.reset()\n",
    "    if render:\n",
    "        env.render()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    new_root = None\n",
    "    for i in range(episode_length):\n",
    "        mcts = MCTS(env, valid_actions, ucb_C, discount, max_actions, render=debug_render, root=new_root)\n",
    "        print(\"Performing MCTS step\")\n",
    "        root, info = mcts.run(num_simulations)\n",
    "        show_root_summary(root, discount)\n",
    "        print(\"Tree info: \", info)\n",
    "        action = root.best_action(discount)\n",
    "        print(\"Action selected from MCTS: \", action, \"({})\".format(action_dict[action]))\n",
    "        new_root = mcts.get_subtree(action)\n",
    "        valid_actions, reward, done = env.step(action)\n",
    "        if render:\n",
    "            env.render()\n",
    "        print(\"Reward received: \", reward)\n",
    "        print(\"Done: \", done)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !y█\n",
      "█ @?n█\n",
      "██████\n",
      "\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.972 - Visit counts=13\n",
      "Action  Up : Q-value=-0.980 - Visit counts=12\n",
      "Action  Left : Q-value=-0.970 - Visit counts=13\n",
      "Action  Right : Q-value=-1.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !y█\n",
      "█@ ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.950 - Visit counts=18\n",
      "Action  Up : Q-value=-0.964 - Visit counts=16\n",
      "Action  Right : Q-value=-0.962 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !y█\n",
      "█@ ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.940 - Visit counts=18\n",
      "Action  Up : Q-value=-0.942 - Visit counts=17\n",
      "Action  Right : Q-value=-0.975 - Visit counts=15\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !y█\n",
      "█@ ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.951 - Visit counts=17\n",
      "Action  Up : Q-value=-0.943 - Visit counts=17\n",
      "Action  Right : Q-value=-0.957 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█@ !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.943 - Visit counts=13\n",
      "Action  Up : Q-value=-0.924 - Visit counts=13\n",
      "Action  Down : Q-value=-0.958 - Visit counts=12\n",
      "Action  Right : Q-value=-0.957 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█@   █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.950 - Visit counts=10\n",
      "Action  Up : Q-value=-0.862 - Visit counts=13\n",
      "Action  Down : Q-value=-0.870 - Visit counts=13\n",
      "Action  Right : Q-value=-0.865 - Visit counts=14\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█@   █\n",
      "█    █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.871 - Visit counts=18\n",
      "Action  Down : Q-value=-0.889 - Visit counts=18\n",
      "Action  Right : Q-value=-0.937 - Visit counts=14\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█@   █\n",
      "█    █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.885 - Visit counts=19\n",
      "Action  Down : Q-value=-0.957 - Visit counts=15\n",
      "Action  Right : Q-value=-0.941 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█@   █\n",
      "█    █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.945 - Visit counts=16\n",
      "Action  Down : Q-value=-0.907 - Visit counts=18\n",
      "Action  Right : Q-value=-0.936 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█@   █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.846 - Visit counts=14\n",
      "Action  Up : Q-value=-0.856 - Visit counts=10\n",
      "Action  Down : Q-value=-0.944 - Visit counts=10\n",
      "Action  Right : Q-value=-0.789 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█ @  █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.959 - Visit counts=8\n",
      "Action  Up : Q-value=-0.943 - Visit counts=9\n",
      "Action  Down : Q-value=-0.871 - Visit counts=11\n",
      "Action  Left : Q-value=-0.931 - Visit counts=9\n",
      "Action  Right : Q-value=-0.808 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.976 - Visit counts=7\n",
      "Action  Up : Q-value=-0.861 - Visit counts=11\n",
      "Action  Down : Q-value=-1.000 - Visit counts=7\n",
      "Action  Left : Q-value=-0.954 - Visit counts=8\n",
      "Action  Right : Q-value=-0.717 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█   @█\n",
      "█  !y█\n",
      "█  ?n█\n",
      "██████\n",
      "\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.858 - Visit counts=13\n",
      "Action  Up : Q-value=-0.926 - Visit counts=10\n",
      "Action  Down : Q-value=-0.725 - Visit counts=18\n",
      "Action  Left : Q-value=-0.960 - Visit counts=9\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !@█\n",
      "█  ?n█\n",
      "██████\n",
      "blessed sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.669 - Visit counts=18\n",
      "Action  Up : Q-value=-0.838 - Visit counts=10\n",
      "Action  Down : Q-value=-0.946 - Visit counts=7\n",
      "Action  Left : Q-value=-0.698 - Visit counts=15\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !@█\n",
      "█  ?n█\n",
      "██████\n",
      "blessed sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.664 - Visit counts=17\n",
      "Action  Up : Q-value=-0.741 - Visit counts=11\n",
      "Action  Down : Q-value=-0.937 - Visit counts=7\n",
      "Action  Left : Q-value=-0.707 - Visit counts=15\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  !@█\n",
      "█  ?n█\n",
      "██████\n",
      "blessed sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.780 - Visit counts=12\n",
      "Action  Up : Q-value=-0.845 - Visit counts=10\n",
      "Action  Down : Q-value=-0.952 - Visit counts=7\n",
      "Action  Left : Q-value=-0.499 - Visit counts=21\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  @ █\n",
      "█  ?n█\n",
      "██████\n",
      "blessed sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.683 - Visit counts=7\n",
      "Action  Up : Q-value=-0.584 - Visit counts=11\n",
      "Action  Down : Q-value=-1.000 - Visit counts=4\n",
      "Action  Left : Q-value=-0.760 - Visit counts=6\n",
      "Action  Right : Q-value=-0.250 - Visit counts=22\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ?n█\n",
      "██████\n",
      "blessed sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.391 - Visit counts=7\n",
      "Action  Up : Q-value=-0.465 - Visit counts=7\n",
      "Action  Down : Q-value=0.000 - Visit counts=32\n",
      "Action  Left : Q-value=-0.697 - Visit counts=4\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█    █\n",
      "█  ?@█\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=16\n",
      "Action  Up : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█    █\n",
      "█  ?@█\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action  Stay : Q-value=0.000 - Visit counts=16\n",
      "Action  Up : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█    █\n",
      "█  ?@█\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=17\n",
      "Action  Up : Q-value=0.000 - Visit counts=16\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Up : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█   @█\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Up : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=12\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "Action  Right : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  @ █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Up : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█   @█\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Up : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█   @█\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=16\n",
      "Action  Down : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Down : Q-value=0.000 - Visit counts=12\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "Action  Right : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "Action  Right : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "Action  Right : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█   @█\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=17\n",
      "Action  Down : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█   @█\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=16\n",
      "Action  Down : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█   @█\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=17\n",
      "Action  Down : Q-value=0.000 - Visit counts=16\n",
      "Action  Left : Q-value=0.000 - Visit counts=17\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "Action  Right : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "Action  Right : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "Action  Right : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█ @  █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Down : Q-value=0.000 - Visit counts=12\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "Action  Right : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█    █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  @ █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  @ █\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=10\n",
      "Action  Up : Q-value=0.000 - Visit counts=10\n",
      "Action  Down : Q-value=0.000 - Visit counts=10\n",
      "Action  Left : Q-value=0.000 - Visit counts=10\n",
      "Action  Right : Q-value=0.000 - Visit counts=10\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=13\n",
      "Action  Up : Q-value=0.000 - Visit counts=12\n",
      "Action  Down : Q-value=0.000 - Visit counts=12\n",
      "Action  Left : Q-value=0.000 - Visit counts=13\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=12\n",
      "Action  Up : Q-value=0.000 - Visit counts=13\n",
      "Action  Down : Q-value=0.000 - Visit counts=13\n",
      "Action  Left : Q-value=0.000 - Visit counts=12\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█    █\n",
      "█  ?@█\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "\n",
      " ----------------------------------------\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=0.000 - Visit counts=17\n",
      "Action  Up : Q-value=0.000 - Visit counts=17\n",
      "Action  Left : Q-value=0.000 - Visit counts=16\n",
      "----------------------------------------\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█   @█\n",
      "█  ? █\n",
      "██████\n",
      "shimmering sword\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "CPU times: user 1min 1s, sys: 645 ms, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R = play_episode_v0(\n",
    "    game_simulator,\n",
    "    episode_length,\n",
    "    ucb_C,\n",
    "    discount,\n",
    "    max_actions,\n",
    "    num_simulations,\n",
    "    debug_render=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent(you, hp=11/11, dmg=0, ac=-3)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(game_simulator.env.agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shimmering sword]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_simulator.env.agent.inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_simulator.env.world.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "██████\n",
      "█ n  █\n",
      "█y   █\n",
      "█ ?  █\n",
      "█@!  █\n",
      "██████\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-1.000 - Visit counts=17\n",
      "Action  Up : Q-value=-0.990 - Visit counts=17\n",
      "Action  Right : Q-value=-1.000 - Visit counts=16\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█ n  █\n",
      "█y   █\n",
      "█@?  █\n",
      "█!   █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.995 - Visit counts=16\n",
      "Action  Up : Q-value=-0.987 - Visit counts=17\n",
      "Action  Down : Q-value=-0.991 - Visit counts=17\n",
      "Action  Right : Q-value=-1.000 - Visit counts=16\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█ n  █\n",
      "█@?  █\n",
      "█    █\n",
      "█!   █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.987 - Visit counts=17\n",
      "Action  Up : Q-value=-0.985 - Visit counts=17\n",
      "Action  Down : Q-value=-1.000 - Visit counts=16\n",
      "Action  Right : Q-value=-1.000 - Visit counts=16\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█@n  █\n",
      "█    █\n",
      "█    █\n",
      "█ !  █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.988 - Visit counts=22\n",
      "Action  Down : Q-value=-1.000 - Visit counts=21\n",
      "Action  Right : Q-value=-0.984 - Visit counts=23\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█ !  █\n",
      "█    █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.985 - Visit counts=18\n",
      "Action  Down : Q-value=-0.987 - Visit counts=18\n",
      "Action  Left : Q-value=-0.983 - Visit counts=18\n",
      "Action  Right : Q-value=-0.985 - Visit counts=18\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█@   █\n",
      "█ ?  █\n",
      "█    █\n",
      "█!   █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.982 - Visit counts=23\n",
      "Action  Down : Q-value=-0.992 - Visit counts=21\n",
      "Action  Right : Q-value=-0.977 - Visit counts=23\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█    █\n",
      "█!   █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.981 - Visit counts=18\n",
      "Action  Down : Q-value=-0.984 - Visit counts=18\n",
      "Action  Left : Q-value=-0.980 - Visit counts=18\n",
      "Action  Right : Q-value=-0.979 - Visit counts=18\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█!   █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.980 - Visit counts=17\n",
      "Action  Down : Q-value=-0.986 - Visit counts=16\n",
      "Action  Left : Q-value=-0.976 - Visit counts=17\n",
      "Action  Right : Q-value=-0.983 - Visit counts=17\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█    █\n",
      "█  ! █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.979 - Visit counts=17\n",
      "Action  Down : Q-value=-0.983 - Visit counts=16\n",
      "Action  Left : Q-value=-0.981 - Visit counts=17\n",
      "Action  Right : Q-value=-0.986 - Visit counts=16\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  0 (Stay)\n",
      "\n",
      "██████\n",
      "█ @  █\n",
      "█    █\n",
      "█  ! █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.987 - Visit counts=17\n",
      "Action  Down : Q-value=-0.992 - Visit counts=16\n",
      "Action  Left : Q-value=-0.987 - Visit counts=16\n",
      "Action  Right : Q-value=-0.980 - Visit counts=17\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█ !  █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.986 - Visit counts=16\n",
      "Action  Down : Q-value=-0.975 - Visit counts=17\n",
      "Action  Left : Q-value=-0.982 - Visit counts=17\n",
      "Action  Right : Q-value=-0.988 - Visit counts=16\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█  ! █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.987 - Visit counts=13\n",
      "Action  Up : Q-value=-0.982 - Visit counts=13\n",
      "Action  Down : Q-value=-0.984 - Visit counts=13\n",
      "Action  Left : Q-value=-0.989 - Visit counts=13\n",
      "Action  Right : Q-value=-0.974 - Visit counts=14\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  4 (Right)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█   @█\n",
      "█ !  █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.979 - Visit counts=16\n",
      "Action  Up : Q-value=-0.979 - Visit counts=16\n",
      "Action  Down : Q-value=-0.984 - Visit counts=16\n",
      "Action  Left : Q-value=-0.983 - Visit counts=15\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  1 (Up)\n",
      "\n",
      "██████\n",
      "█   @█\n",
      "█    █\n",
      "█    █\n",
      "█ !  █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.982 - Visit counts=21\n",
      "Action  Down : Q-value=-0.986 - Visit counts=21\n",
      "Action  Left : Q-value=-0.970 - Visit counts=23\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█  @ █\n",
      "█    █\n",
      "█    █\n",
      "█  ! █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.977 - Visit counts=18\n",
      "Action  Down : Q-value=-0.974 - Visit counts=18\n",
      "Action  Left : Q-value=-0.976 - Visit counts=18\n",
      "Action  Right : Q-value=-0.977 - Visit counts=18\n",
      "Tree info:  {'max_tree_depth': 4}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█  @ █\n",
      "█ !  █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.984 - Visit counts=13\n",
      "Action  Up : Q-value=-0.977 - Visit counts=13\n",
      "Action  Down : Q-value=-0.973 - Visit counts=14\n",
      "Action  Left : Q-value=-0.987 - Visit counts=13\n",
      "Action  Right : Q-value=-0.975 - Visit counts=14\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  2 (Down)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█  @ █\n",
      "█ !  █\n",
      "██████\n",
      "Reward received:  0\n",
      "Done:  False\n",
      "Performing MCTS step\n",
      "Action  Stay : Q-value=-0.987 - Visit counts=12\n",
      "Action  Up : Q-value=-0.985 - Visit counts=13\n",
      "Action  Down : Q-value=-0.981 - Visit counts=13\n",
      "Action  Left : Q-value=-0.979 - Visit counts=13\n",
      "Action  Right : Q-value=-0.985 - Visit counts=12\n",
      "Tree info:  {'max_tree_depth': 3}\n",
      "Action selected from MCTS:  3 (Left)\n",
      "\n",
      "██████\n",
      "█    █\n",
      "█    █\n",
      "█ !  █\n",
      "█    █\n",
      "██████\n",
      "Reward received:  -1\n",
      "Done:  True\n",
      "CPU times: user 8.73 s, sys: 217 ms, total: 8.95 s\n",
      "Wall time: 9.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R = play_episode_v1(\n",
    "    game_simulator,\n",
    "    episode_length,\n",
    "    ucb_C,\n",
    "    discount,\n",
    "    max_actions,\n",
    "    num_simulations,\n",
    "    debug_render=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing a value network\n",
    "\n",
    "TODO\n",
    "- get the state to predict the value\n",
    "- define a target with which to train the value net\n",
    "- choose on which data to train (whole trajectory? just one trajectory or many?)\n",
    "- **make the simulations faster** (function to set the state of the simulator instead of having to make a deepcopy every time?)\n",
    "- define training cycle\n",
    "\n",
    "EXTRA\n",
    "- use some muti-threaded application, like torch.multiprocessing, to run many episodes in parallel; adapt code from IMPALA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
